"""
Ultimate ES Transformer Training Launcher
Coordinates everything for maximum performance on your powerful hardware
"""

import os
import sys
import json
import time
import subprocess
from pathlib import Path
import torch

class UltimateESTrainer:
    """Complete training orchestrator"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.venv_python = self.project_root / "venv" / "Scripts" / "python.exe"
        self.models_dir = self.project_root / "models"
        self.models_dir.mkdir(exist_ok=True)
        
    def check_hardware(self):
        """Comprehensive hardware check"""
        print("ğŸ” Hardware Analysis")
        print("=" * 40)
        
        # CPU info
        import psutil
        print(f"ğŸ’» CPU Cores: {psutil.cpu_count()} physical, {psutil.cpu_count(logical=False)} logical")
        print(f"ğŸ’½ RAM: {psutil.virtual_memory().total / 1e9:.1f} GB")
        
        # GPU info
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name()
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"ğŸ”¥ GPU: {gpu_name}")
            print(f"ğŸ“Š GPU Memory: {gpu_memory:.1f} GB")
            
            # Calculate optimal settings
            if gpu_memory >= 20:
                batch_size = 128
                model_size = "extra_large"
            elif gpu_memory >= 12:
                batch_size = 64
                model_size = "large" 
            elif gpu_memory >= 8:
                batch_size = 32
                model_size = "medium"
            else:
                batch_size = 16
                model_size = "small"
                
            print(f"ğŸ¯ Recommended batch size: {batch_size}")
            print(f"ğŸ—ï¸ Recommended model size: {model_size}")
            
            return {
                'gpu_available': True,
                'batch_size': batch_size,
                'model_size': model_size
            }
        else:
            print("âš ï¸ No CUDA GPU detected")
            return {
                'gpu_available': False,
                'batch_size': 8,
                'model_size': 'small'
            }
    
    def create_optimized_config(self, hardware_info):
        """Create hardware-optimized configuration"""
        
        model_configs = {
            'small': {'d_model': 256, 'nhead': 8, 'num_layers': 6},
            'medium': {'d_model': 512, 'nhead': 16, 'num_layers': 8},
            'large': {'d_model': 768, 'nhead': 24, 'num_layers': 12},
            'extra_large': {'d_model': 1024, 'nhead': 32, 'num_layers': 16}
        }
        
        model_config = model_configs[hardware_info['model_size']]
        
        config = {
            'hardware': hardware_info,
            'model': {
                **model_config,
                'seq_length': 250,  # ~10 hours of 1-min data
                'dropout': 0.1,
                'num_classes': 3
            },
            'training': {
                'batch_size': hardware_info['batch_size'],
                'learning_rate': 1e-4,
                'epochs': 150,
                'early_stopping_patience': 15,
                'mixed_precision': hardware_info['gpu_available'],
                'gradient_clip': 1.0
            },
            'data': {
                'data_period': '5y',  # 5 years of data
                'validation_split': 0.2,
                'test_split': 0.1,
                'num_workers': min(8, os.cpu_count()),
                'pin_memory': hardware_info['gpu_available']
            },
            'optimization': {
                'compile_model': True,
                'use_amp': hardware_info['gpu_available'],
                'dataloader_optimization': True
            }
        }
        
        # Save config
        config_path = self.project_root / "ultimate_training_config.json"
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"ğŸ“„ Optimized config saved: {config_path}")
        return config
    
    def run_training(self, config):
        """Launch optimized training"""
        print("\nğŸš€ Launching Ultimate ES Transformer Training")
        print("=" * 60)
        
        # Create training script call
        training_script = self.project_root / "ml-models" / "training" / "gpu_transformer_trainer.py"
        
        if not training_script.exists():
            print(f"âŒ Training script not found: {training_script}")
            return False
        
        # Launch training with optimal settings
        cmd = [
            str(self.venv_python),
            str(training_script),
            "--config", str(self.project_root / "ultimate_training_config.json")
        ]
        
        print(f"ğŸ”§ Command: {' '.join(cmd)}")
        print("ğŸ• Starting training... (This will take 2-6 hours)")
        print("ğŸ’¡ You can monitor progress in another terminal with: python monitor_training.py")
        print("-" * 60)
        
        try:
            # Start training process
            process = subprocess.Popen(
                cmd,
                cwd=str(self.project_root),
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                universal_newlines=True,
                bufsize=1
            )
            
            # Stream output in real-time
            for line in process.stdout:
                print(line.rstrip())
            
            process.wait()
            
            if process.returncode == 0:
                print("\nğŸ‰ Training completed successfully!")
                return True
            else:
                print(f"\nâŒ Training failed with exit code: {process.returncode}")
                return False
                
        except Exception as e:
            print(f"âŒ Error during training: {e}")
            return False
    
    def create_monitoring_dashboard(self):
        """Create real-time monitoring dashboard"""
        dashboard_script = '''
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import pandas as pd
import numpy as np
from datetime import datetime
import json
import time

class TrainingMonitor:
    def __init__(self):
        self.fig, ((self.ax1, self.ax2), (self.ax3, self.ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        self.fig.suptitle('ES Transformer Training Monitor', fontsize=16)
        
        # Initialize data storage
        self.epochs = []
        self.train_losses = []
        self.val_losses = []
        self.train_accs = []
        self.val_accs = []
        
    def animate(self, frame):
        # Try to read training progress
        try:
            with open('training_progress.json', 'r') as f:
                data = json.load(f)
            
            if 'epochs' in data:
                self.epochs = data['epochs']
                self.train_losses = data['train_losses']
                self.val_losses = data['val_losses']
                self.train_accs = data['train_accs']
                self.val_accs = data['val_accs']
        except:
            pass
        
        # Clear previous plots
        for ax in [self.ax1, self.ax2, self.ax3, self.ax4]:
            ax.clear()
        
        if len(self.epochs) > 0:
            # Loss plot
            self.ax1.plot(self.epochs, self.train_losses, label='Train Loss', color='blue')
            self.ax1.plot(self.epochs, self.val_losses, label='Val Loss', color='red')
            self.ax1.set_title('Training & Validation Loss')
            self.ax1.set_xlabel('Epoch')
            self.ax1.set_ylabel('Loss')
            self.ax1.legend()
            self.ax1.grid(True)
            
            # Accuracy plot
            self.ax2.plot(self.epochs, self.train_accs, label='Train Acc', color='green')
            self.ax2.plot(self.epochs, self.val_accs, label='Val Acc', color='orange')
            self.ax2.set_title('Training & Validation Accuracy')
            self.ax2.set_xlabel('Epoch')
            self.ax2.set_ylabel('Accuracy (%)')
            self.ax2.legend()
            self.ax2.grid(True)
            
            # Learning rate (if available)
            self.ax3.set_title('Learning Rate Schedule')
            self.ax3.set_xlabel('Epoch')
            self.ax3.set_ylabel('Learning Rate')
            self.ax3.grid(True)
            
            # GPU utilization (if available)
            self.ax4.set_title('System Resources')
            self.ax4.set_xlabel('Time')
            self.ax4.set_ylabel('Usage (%)')
            self.ax4.grid(True)
        else:
            self.ax1.text(0.5, 0.5, 'Waiting for training data...', 
                         ha='center', va='center', transform=self.ax1.transAxes)
    
    def start_monitoring(self):
        ani = animation.FuncAnimation(self.fig, self.animate, interval=5000)
        plt.tight_layout()
        plt.show()

if __name__ == "__main__":
    monitor = TrainingMonitor()
    monitor.start_monitoring()
'''
        
        with open(self.project_root / "training_dashboard.py", 'w') as f:
            f.write(dashboard_script)
        
        print("ğŸ“Š Training dashboard created: training_dashboard.py")
    
    def run_complete_pipeline(self):
        """Run the complete training pipeline"""
        print("ğŸ¯ Ultimate ES Transformer Training Pipeline")
        print("=" * 60)
        print("ğŸ‹ï¸ Leveraging your powerful hardware for maximum performance")
        print("ğŸ’ª Expected improvements over basic model:")
        print("   â€¢ 10-15% higher accuracy")
        print("   â€¢ Better pattern recognition")
        print("   â€¢ Longer sequence understanding")
        print("   â€¢ More robust predictions")
        print("=" * 60)
        
        # Step 1: Hardware analysis
        hardware_info = self.check_hardware()
        
        # Step 2: Create optimized config
        config = self.create_optimized_config(hardware_info)
        
        # Step 3: Create monitoring tools
        self.create_monitoring_dashboard()
        
        # Step 4: Confirm start
        print(f"\nğŸ“‹ Training Configuration:")
        print(f"   Model: {config['model']['d_model']}-dim, {config['model']['num_layers']} layers")
        print(f"   Batch Size: {config['training']['batch_size']}")
        print(f"   Sequence Length: {config['model']['seq_length']} timesteps")
        print(f"   Data Period: {config['data']['data_period']}")
        print(f"   Expected Training Time: {'2-4 hours' if hardware_info['gpu_available'] else '8-12 hours'}")
        
        response = input(f"\nğŸš€ Start ultimate transformer training? (y/n): ")
        if response.lower() != 'y':
            print("âŒ Training cancelled")
            return
        
        # Step 5: Launch training
        success = self.run_training(config)
        
        if success:
            print("\nğŸ‰ ULTIMATE TRAINING COMPLETED!")
            print("=" * 50)
            print("ğŸ“ Your trained model is ready:")
            print(f"   Location: {self.models_dir}")
            print("   Files: es_transformer_best.pt")
            print("\nğŸ“‹ Next Steps:")
            print("1. ğŸ”„ Restart NinjaTrader 8")
            print("2. ğŸ® Open ES ML Trading System")
            print("3. âœ¨ Enjoy enhanced ML predictions!")
        else:
            print("\nâŒ Training encountered issues")
            print("ğŸ’¡ Check the error messages above")

def main():
    trainer = UltimateESTrainer()
    trainer.run_complete_pipeline()

if __name__ == "__main__":
    main()